{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58e923f",
   "metadata": {},
   "source": [
    "# Project 1: Air Quality with Sequential CV\n",
    "Task #3\n",
    "Jacob A. Fericy\n",
    "\n",
    "This project notebook aims to predict **benzene concentration** `C6H6(GT)` from the **UCI Air Quality Dataset** (UCI ML Repo id=360) and compares two models as we develop a cross-validation algorithm over both models. More specifically we compare these models:\n",
    "\n",
    "- **_Time-only_** linear model: Day\n",
    "- **_Full_** linear model: Day + CO(GT) + T + RH + AH\n",
    "\n",
    "We evaluate with a type of walk‑forward (one‑step‑ahead) validation. We fit on days 1,2,..,d, predict day d + 1, compute MSE, and sum the MSE over the evaluation window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89795cb7",
   "metadata": {},
   "source": [
    "## 1) Imports & Functions\n",
    "\n",
    "**oneStepMSE**: trains on all rows up to a given day and predicts the following day.  \n",
    "**sequentialCVMSE** loops forward and sums the one‑step MSE values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25a1ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def oneStepMSE(X, y, day, day_col=\"Day\"):\n",
    "    \n",
    "    #seperate training versus test for the sake of the model\n",
    "    train_mask = X[day_col] <= day\n",
    "    test_mask = X[day_col] == (day + 1)\n",
    "    X_train, y_train = X.loc[train_mask], y.loc[train_mask]\n",
    "    X_test, y_test = X.loc[test_mask], y.loc[test_mask]\n",
    "\n",
    "    #ensure next day obs is there\n",
    "    if len(X_test) != 1:\n",
    "        print(\"Exception: Next-Day observation not present!\")\n",
    "        return None\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return mean_squared_error(y_test, y_pred)\n",
    "\n",
    "def sequentialCVMSE(X, y, start_day=250, day_col=\"Day\"):\n",
    "\n",
    "    max_day = int(X[day_col].max())\n",
    "\n",
    "    mse_sum = 0.0\n",
    "    \n",
    "    #iterate through days, one -step ahead MSE until evaluation fails\n",
    "    for d in range(start_day, max_day):\n",
    "        mse = oneStepMSE(X, y, day=d, day_col=day_col)\n",
    "        if mse is None:\n",
    "            #condition kick-out if there is nothing to add\n",
    "            break\n",
    "        mse_sum += mse \n",
    "    return mse_sum\n",
    "\n",
    "def fitEvaluateModel(X_train, X_test, y_train, y_test):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    return model, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4da1b4b",
   "metadata": {},
   "source": [
    "## 2) Load and Clean Data\n",
    "\n",
    "We fetch the dataset and keep only the columns we need for this review. \n",
    "\n",
    "In this dataset, the value **-200** is a missing-value sentinel that needs to be filtered out.  \n",
    "Here we keep your original filter logic: filter each variable sequentially to ensure we have the proper dataset to test.\n",
    "\n",
    "Then we parse Date on the filtered frame and drop any rows where the date still can’t be parsed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87e40aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = fetch_ucirepo(id=360)\n",
    "df = air_quality.data.features.copy()\n",
    "\n",
    "df_clean = df.copy()\n",
    "vars_to_check = [\"C6H6(GT)\", \"CO(GT)\", \"T\", \"RH\", \"AH\"]\n",
    "\n",
    "#cleans dataset\n",
    "for v in vars_to_check:\n",
    "    df_clean = df_clean[df_clean[v] != -200]\n",
    "    \n",
    "df[\"Date\"] = df[\"Date\"].astype(str).str.strip()\n",
    "dt1 = pd.to_datetime(df[\"Date\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "dt2 = pd.to_datetime(df[\"Date\"], errors=\"coerce\", dayfirst=True)\n",
    "df[\"Date\"] = dt1.fillna(dt2)\n",
    "\n",
    "df_clean['Date'] = pd.to_datetime(df_clean['Date'], errors='coerce')\n",
    "df_clean = df_clean.sort_values('Date', ascending=True).reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afe154d",
   "metadata": {},
   "source": [
    "## 3) Aggregate Day Data\n",
    "\n",
    "The raw data is higher-frequency (hourly).  \n",
    "We aggregate to **daily means** and create a sequential day index used for time ordering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7a381c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregates variables to daily means\n",
    "df_day = (\n",
    "    df_clean\n",
    "    .groupby(\"Date\", as_index=False)[vars_to_check]\n",
    "    .mean()\n",
    "    .sort_values(\"Date\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_day[\"Day\"] = np.arange(1, len(df_day) + 1)\n",
    "\n",
    "df = df_day.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1e946c",
   "metadata": {},
   "source": [
    "## 4) Build features and run walk-forward validation\n",
    "\n",
    "We compare:\n",
    "- X_time = [Day]\n",
    "- X_full = [Day, CO(GT), T, RH, AH]\n",
    "\n",
    "Then compute summed one-step-ahead MSE starting at **start_day = 250**.\n",
    "\n",
    "Condition: if there are fewer than 252 daily rows after cleaning, we automatically shift start_day to half the series length so the code still runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95e91659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily rows: 347 | start_day used: 250\n",
      "Overall SUM MSE (time only): 1820.9283445426604\n",
      "Overall SUM MSE (full predictors): 496.46303567275567\n"
     ]
    }
   ],
   "source": [
    "X_time = df_day[[\"Day\"]]\n",
    "X_full = df_day[[\"Day\", \"CO(GT)\", \"T\", \"RH\", \"AH\"]]\n",
    "y = df_day[\"C6H6(GT)\"]\n",
    "\n",
    "#ensures starting day allows one split given the data we are pulling from upstream\n",
    "start_day = 250\n",
    "if len(df_day) <= start_day + 1:\n",
    "    start_day = max(1, len(df_day) // 2)\n",
    "\n",
    "mse_sum_time = sequentialCVMSE(X_time, y, start_day = start_day, day_col = \"Day\")\n",
    "mse_sum_full = sequentialCVMSE(X_full, y, start_day = start_day, day_col = \"Day\")\n",
    "\n",
    "print(\"Daily rows:\", len(df_day), \"| start_day used:\", start_day)\n",
    "print(\"Overall SUM MSE (time only):\", mse_sum_time)\n",
    "print(\"Overall SUM MSE (full predictors):\", mse_sum_full)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3672e476",
   "metadata": {},
   "source": [
    "## 5) Model Fit\n",
    "\n",
    "We do the following:\n",
    "- Run MLR\n",
    "- Run SLR\n",
    "- Output and run final completed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdc533b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLR Test MSE: 4.382\n",
      "MLR Test MSE: 3.226\n",
      "MLR performs better based on MSE.\n",
      "\n",
      "Best model fitted on full dataset.\n",
      "Coefficients:\n",
      "  CO(GT): 4.771\n",
      "  T: 0.120\n",
      "  RH: -0.016\n",
      "  AH: 0.689\n",
      "Intercept: -1.838\n"
     ]
    }
   ],
   "source": [
    "target_col = \"C6H6(GT)\"\n",
    "predictor_cols = [\"CO(GT)\", \"T\", \"RH\", \"AH\"]\n",
    "needed_cols = [\"Date\", target_col] + predictor_cols\n",
    "\n",
    "X = df[predictor_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.25, random_state = 451)\n",
    "\n",
    "X_train_slr = X_train[[\"CO(GT)\"]]\n",
    "X_test_slr = X_test[[\"CO(GT)\"]]\n",
    "\n",
    "slr_model, slr_mse = fitEvaluateModel(\n",
    "    X_train_slr, X_test_slr, y_train, y_test\n",
    ")\n",
    "\n",
    "print(f\"SLR Test MSE: {slr_mse:.3f}\")\n",
    "\n",
    "mlr_model, mlr_mse = fitEvaluateModel(\n",
    "    X_train, X_test, y_train, y_test\n",
    ")\n",
    "\n",
    "print(f\"MLR Test MSE: {mlr_mse:.3f}\")\n",
    "\n",
    "if mlr_mse < slr_mse:\n",
    "    print(\"MLR performs better based on MSE.\")\n",
    "else:\n",
    "    print(\"SLR performs better based on MSE.\")\n",
    "\n",
    "best_model = LinearRegression()\n",
    "best_model.fit(X, y)\n",
    "\n",
    "print(\"\\nBest model fitted on full dataset.\")\n",
    "print(\"Coefficients:\")\n",
    "for col, coef in zip(predictor_cols, best_model.coef_):\n",
    "    print(f\"  {col}: {coef:.3f}\")\n",
    "\n",
    "print(f\"Intercept: {best_model.intercept_:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d3bf20",
   "metadata": {},
   "source": [
    "## 6) Conclusions\n",
    "\n",
    "Above we extended the model to include multiple predictors CO(GT), temperature (T), relative humidity (RH), and absolute humidity (AH). From a expertise perspective, this makes sense given benzene concentration is affected not only by emissions but also by atmospheric conditions that influence dispersion and chemical behavior. As such, there are many potential causes to consider.\n",
    "\n",
    "When looking holistically, because MLR uses more relevant information, we would expect the Mean Squared Error (MSE) to be lower than that of SLR. We compare the models using Mean Squared Error (MSE) given MSE penalizes larger prediction errors, making it a good driver for regression where large deviations may be problematic.\n",
    "\n",
    "As we look at the results, we see indeed that MLR is the optimal model. After identifying MLR as the preferred model, we refit it using the full dataset to obtain the most reliable parameter estimates. This final model would be the best choice for interpretation or future prediction tasks using this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
