{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOkpx/Iep7+E6gHLNGGMeQO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tort-cam/ST-554-P1/blob/main/Task2/ST554Proj1EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Project 1 Task 2: Exploratory Data Analysis\n",
        "Author : Cameron Mullaney\n",
        "\n",
        "In this notebook, we will perform an **EDA** (exploratory data analysis) on the **Air Quality dataset** provided by UCI.\n",
        "\n",
        "This process features a few key steps:\n",
        "- Loading in the data\n",
        "- Basic data validation\n",
        "- Investigate missing values\n",
        "- Clean up data (Handle missing values)\n",
        "- Investigate distributions (the fun part!)\n",
        "    - This is where we will create some preliminary figures, and try to get a general idea of the patterns that may exist in this data\n",
        "    - Our exploration revolves around the **Benzene levels** specifically, which dramatically reduces the number of relationships we have to explore.\n",
        "    - This section will heavily feature plots, as well as single and multiple linear regression models.\n",
        "\n",
        "\n",
        "This process will provide us direction for future work with this dataset, better informing the variables we would choose to investigate further.\n"
      ],
      "metadata": {
        "id": "nShx2xUuOVW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading in the data from UCI and installing modules I'll need.\n",
        "\n",
        "Because I am using a variety of methods to evaluate the data, I am using *quite a few* different modules."
      ],
      "metadata": {
        "id": "j23XVgBLzgz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo ## This module allows us to pull in the UCI data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VUTRe6Zu_Ys",
        "outputId": "0ac7895c-e3e9-4474-c347-a8b48030d311",
        "collapsed": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.12/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2026.1.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "cYSVreC8s09C"
      },
      "outputs": [],
      "source": [
        "## These will allow us to handle, visualize and analyze our data.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "from sklearn import linear_model\n",
        "import sklearn.metrics as metrics\n",
        "import plotly.express as px\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "air_quality = fetch_ucirepo(id=360) #Pull in UCI data\n",
        "aq = pd.DataFrame(air_quality.data.features)\n",
        "#This air_quality object contains 2 separate datasets,\n",
        "#and we only need one, the \"features\" subset."
      ],
      "metadata": {
        "id": "ZJEPuqvVuC2c",
        "outputId": "88a4510f-4c70-4f9c-dd6a-cfdc565048c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConnectionError",
          "evalue": "Error connecting to server",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[1;32m   1345\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1338\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1383\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1332\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m             self.sock = self._context.wrap_socket(self.sock,\n\u001b[0m\u001b[1;32m   1480\u001b[0m                                                   server_hostname=server_hostname)\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;31m# ctx._wrap_socket()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         return self.sslsocket_class._create(\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1318\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1010)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ucimlrepo/fetch.py\u001b[0m in \u001b[0;36mfetch_ucirepo\u001b[0;34m(name, id)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_default_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcafile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcertifi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    533\u001b[0m                                   '_open', req)\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[1;32m   1393\u001b[0m                                 context=self._context)\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1010)>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1476978001.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mair_quality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_ucirepo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m360\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Pull in UCI data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mair_quality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#This air_quality object contains 2 separate datasets,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#and we only need one, the \"features\" subset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ucimlrepo/fetch.py\u001b[0m in \u001b[0;36mfetch_ucirepo\u001b[0;34m(name, id)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error connecting to server'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# verify that dataset exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionError\u001b[0m: Error connecting to server"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Understanding how this data is stored\n",
        "This data is almost entirely numeric, with the exception of `Date` and `Time`, and I will convert those to a usable value later. All other columns are either integers or floats."
      ],
      "metadata": {
        "id": "7UUelrDKlOLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aq.info()"
      ],
      "metadata": {
        "id": "12fq9ki2vZfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We were told we can ignore the \"True\" pollutant measurements, other than Benzene, so I'm removing columns with a \"(GT)\" in them, other than C6H6 (Benzene)"
      ],
      "metadata": {
        "id": "_5ty4E-M92L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aq_sub = aq.iloc[:,[0,1,3,5,6,8,10,11,12,13,14]] ## Keeping all rows, but only columns 0, 1, 3, etc."
      ],
      "metadata": {
        "id": "6f0GOQh-9Wlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking a look at aq_sub, it seems good! Removed what we don't need."
      ],
      "metadata": {
        "id": "poQmsrJ1-uhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aq_sub"
      ],
      "metadata": {
        "id": "vU2FAXgV9xSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Basic Data Validation"
      ],
      "metadata": {
        "id": "RNKZgkz_mSmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking a quick peek at what we're working with, using the `.describe()` method.\n",
        "Looks like there are a lot of -200 values, which represent \"missing values\""
      ],
      "metadata": {
        "id": "8gz3qTZu0WIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aq_sub.describe()"
      ],
      "metadata": {
        "id": "Xcwnl5rWz_iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Determine Rate of Missing Values"
      ],
      "metadata": {
        "id": "Q_Q41ylymXxr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how many missing values there are: Looks like we've got ~3300, but only in 366 rows. This suggests that these missing values are often stacked in single rows. Here, `na_ct` will count missing values, while `row_ct` will count the number of rows containing missing values."
      ],
      "metadata": {
        "id": "8JlFOp9e3Lk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "na_ct = 0 ## Count of missing values\n",
        "row_ct = 0 ## Number of rows with >0 missing values\n",
        "test = False ## Boolean for each row's status\n",
        "for row in aq_sub.iloc[:,2:].values: ## Ignore \"Date\" and \"Time\" Columns\n",
        "  test = False ## Reset to False every loop\n",
        "  for val in row:\n",
        "    if math.isclose(val, -200): ## Add 1 to na_ct for every \"-200\"\n",
        "      na_ct+=1\n",
        "      test = True ## If we find a missing value, this marks the row\n",
        "  if test:\n",
        "    row_ct+=1 ## After each row, if test == True, that row contains a missing value, so +1 to row count.\n",
        "print (\"Missing Values:\\t\",str(na_ct))\n",
        "print (\"Rows w/ Missing Values:\\t\", row_ct)"
      ],
      "metadata": {
        "id": "qhPCzE3_1rqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Clean up data"
      ],
      "metadata": {
        "id": "pg4c4O6UmdGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay! Let's replace these -200 values with `NaN` values, and then we can use `.dropna()` to remove them. \\\n",
        "Our df has gotten 366 rows shorter, the number we were expecting from the last cell's `row_ct` value. I've decided on `aqf` as our dataFrame name, for \"Air Quality Fixed\".\n",
        "We've also renamed our columns for clarity. Now, another look at `.describe()` shows us meaningful summaries of our data: We know each variables mean, median, st.dev and much more!"
      ],
      "metadata": {
        "id": "L-be4zoyCisp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aqtemp = aq_sub.replace(float(-200), np.nan) ## Replace \"-200\" with \"NaN\"\n",
        "aqf = aqtemp.dropna() ## Get rid of all rows with an \"NaN\"\n",
        "print(len(aq_sub)-len(aqf))\n",
        "aqf = aqf.rename(columns={'C6H6(GT)': 'B', 'PT08.S1(CO)': 'CO', \\\n",
        "                          'PT08.S2(NMHC)': 'NMHC', 'PT08.S3(NOx)': 'NOx', \\\n",
        "                          'PT08.S4(NO2)': 'NO2', 'PT08.S5(O3)': 'O3'})\n",
        "aqf.describe()"
      ],
      "metadata": {
        "id": "4W43Vp1C4amG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I am reformatting date and time into a single column for simplicity, and using `datetime` to treat them as a datetime object."
      ],
      "metadata": {
        "id": "DkOTwokmOem9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aqf[\"DTtemp\"] = aqf['Date'] + \" \" + aqf[\"Time\"] ##New column which concatenates \"Date\" and \"Time\"\n",
        "aqf[\"datetime\"] = pd.to_datetime((aqf['DTtemp']), format = 'mixed', dayfirst = False)\n",
        "aqf = aqf.drop(\"DTtemp\", axis = 1)"
      ],
      "metadata": {
        "id": "UMgTwBbUE-Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Investigate Distributions"
      ],
      "metadata": {
        "id": "WHbrF4hRmjMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Benzene Histogram\n",
        "Now that we've cleaned up these missing values, let's get to work! Looks like Benzene (B) is pretty right skewed, with most values being <20.\n"
      ],
      "metadata": {
        "id": "JwEjRBfjC6K0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(aqf[\"B\"])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kXC6R3JdC9tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Benzene by Datetime\n",
        "Looks like the `datetime` column is working as intended! Noticing a drop in Benzene values around August 2004"
      ],
      "metadata": {
        "id": "FPIJPEA8Ly_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(aqf[\"datetime\"], aqf[\"B\"], s = .05, c = \"black\")\n",
        "plt.title(\"Benzene levels over time\")"
      ],
      "metadata": {
        "id": "Sx0a386iFI9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Benzene by Everything (W/ SLR)\n",
        "Here we've got scatter plots of Benzene levels with every other numeric variable, just to get an idea of what our data looks like. Immediately, it seems like Benzene is correlated strongly with CO, NOx, NO2, and O3. NMHC looks a little *too* nice, where it seems like they might be measuring the same thing, just on different scales. I'll need some software math to figure out if temp, relative humidity, or absolute humidity are correlated with Benzene."
      ],
      "metadata": {
        "id": "P9aiSdH-MPsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notB = aqf.columns.drop([\"B\", \"Date\", \"Time\", \"datetime\"])\n",
        "every = sns.pairplot(kind = \"reg\", data = aqf, y_vars = \"B\", x_vars = notB, markers = \"+\",\\\n",
        "                    plot_kws = {'line_kws':{'lw' : 2, 'color':\"darkblue\"}, 'scatter_kws':{'alpha':.1, 's':2}})"
      ],
      "metadata": {
        "id": "qFIPSP4BIjQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Datetime by Everything\n",
        "Here, I've set the Y axis to `datetime`, showing changes in these variables over the 1 year range. Seems like a lot of the pollution variables drop in August 2004."
      ],
      "metadata": {
        "id": "HQYtW-x6g9QU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notDT = aqf.columns.drop([\"Date\", \"Time\", \"datetime\"]) ## List of columns to avoid in this set of plots\n",
        "every = sns.pairplot(kind = \"scatter\", data = aqf, y_vars = \"datetime\", x_vars = notDT, markers = \"+\", plot_kws = {'s' : 2})"
      ],
      "metadata": {
        "id": "R4zz08EXdoIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Simple (Single) Linear Models\n",
        "Let's look at some linear model values!\n",
        "Here we see that NMHC and Benzene are very strongly correlated (Rsquared of .965), which makes sense given their *too* nice graph earlier."
      ],
      "metadata": {
        "id": "kmid8AIcPv8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(aqf['NMHC'], aqf['B'], test_size=0.2, random_state=42)\n",
        "co = linear_model.LinearRegression()\n",
        "co.fit(X_train.values.reshape(-1,1), y_train.values)\n",
        "COpred = co.predict(X_train.values.reshape(-1,1))\n",
        "print(\"Linear Model for NMHC and Benzene\", \"\\nIntercept \\t:\", co.intercept_, \"\\nCoefficient\\t:\", co.coef_, \\\n",
        "      \"\\nRMSE\\t\\t:\", np.sqrt(metrics.mean_squared_error(y_train.values, COpred)), \"\\nRsquared\\t:\", \\\n",
        "      co.score(X_test.values.reshape(-1,1), y_test))"
      ],
      "metadata": {
        "id": "V4eDNdFhPqVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I've put together a function we can use to find some simple linear regression values. Just need to provide the column names of the 2 variables."
      ],
      "metadata": {
        "id": "GMe4CGz6ulUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lmtest(v1, v2, graph = False):\n",
        "  \"\"\"\n",
        "  This function takes in two column names from this data\n",
        "  (NOT ANY DATA SHEET JUST THIS ONE)\n",
        "  and returns some important regression values, as well as a color-coded figure\n",
        "  if you supply True for graph\n",
        "  \"\"\"\n",
        "  X_train, X_test, y_train, y_test = train_test_split(aqf[v1], aqf[v2], test_size=0.2, random_state=42) ## Separate out data into train and test sets\n",
        "\n",
        "  lm = linear_model.LinearRegression()\n",
        "  lm.fit(X_train.values.reshape(-1,1), y_train.values)\n",
        "  if graph: ## If it's wanted, this will produce a best fit line for the data.\n",
        "    sns.regplot(x = X_train, y = y_train, marker = \"+\", scatter_kws = {'s' : 1}, \\\n",
        "              line_kws ={'color': \"darkblue\"}, label = \"Train\")\n",
        "    sns.scatterplot(x = X_test, y = y_test, marker = \"o\", s = 1, color = \"red\", label = \"Test\")\n",
        "    plt.legend()\n",
        "  pred = lm.predict(X_train.values.reshape(-1,1))\n",
        "  print(\"Linear Model for \" + v1 + \" and \" + v2, \\\n",
        "        \"\\nIntercept \\t:\", lm.intercept_, \\\n",
        "        \"\\nCoefficient\\t:\", lm.coef_, \\\n",
        "        \"\\nRMSE\\t\\t:\", np.sqrt(metrics.mean_squared_error(y_train.values, pred)), \\\n",
        "        \"\\nRsquared\\t:\", lm.score(X_test.values.reshape(-1,1), y_test))"
      ],
      "metadata": {
        "id": "DSIuzNGIqGnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I am using this `lmtest` function to look at the relationship between NO2 and Benzene"
      ],
      "metadata": {
        "id": "XTENZQLh_Heb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lmtest(\"NO2\", \"B\")"
      ],
      "metadata": {
        "id": "i4X6-eyyrjCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating Categoricals\n",
        "Creating ordered categories for Temp using `.describe()` quartiles from earlier, separating out the top and bottom 25% of values as \"low\" and \"high\""
      ],
      "metadata": {
        "id": "NjhZUPnXFiTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Temperature"
      ],
      "metadata": {
        "id": "cOTbBLoZQ2gJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aqf['Tcat'] = \"M\"\n",
        "aqf.loc[aqf['T']> 24.4, 'Tcat'] = \"H\" ##Top 25% of temps considered high\n",
        "aqf.loc[aqf['T']< 11.8, 'Tcat'] = \"L\" ## Bottom 25% considered low\n",
        "aqf['Tcat'] = aqf.Tcat.astype(\"category\")\n",
        "order = [\"L\", \"M\", \"H\"]\n",
        "cat_dtype = pd.CategoricalDtype(categories=order, ordered=True)\n",
        "aqf['Tcat'] = aqf['Tcat'].astype(cat_dtype) ## We will treat this \"Tcat\" column as a category"
      ],
      "metadata": {
        "id": "uXj7Hl-EFkud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we see that in general, as temp increases (From low -> medium -> high), mean Benzene level also increases."
      ],
      "metadata": {
        "id": "1FwanYkYMlId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is reflected in the numeric summary as well."
      ],
      "metadata": {
        "id": "8oYk-CJSQBS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aqf.boxplot(column = ['B'], by = \"Tcat\")\n",
        "plt.title(\"Benzene by Temperature\")\n",
        "plt.xlabel(\"Temperature Level (High, Low, Medium)\")\n",
        "aqf.groupby(\"Tcat\", observed = False)[\"B\"].mean()"
      ],
      "metadata": {
        "id": "2CMpvutoG-R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Relative Humidity"
      ],
      "metadata": {
        "id": "5Lci_6KlQ57T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aqf['RHcat'] = \"M\"\n",
        "aqf.loc[aqf['RH']> 62.5, 'RHcat'] = \"H\" ##Same as for temperature\n",
        "aqf.loc[aqf['RH']< 35.8, 'RHcat'] = \"L\"\n",
        "aqf['RHcat'] = aqf.RHcat.astype(\"category\")\n",
        "aqf['RHcat'] = aqf['RHcat'].astype(cat_dtype)"
      ],
      "metadata": {
        "id": "OPKKaX0bNnFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't see nearly as much change as Relative Humidity increases, though there is still a slight change."
      ],
      "metadata": {
        "id": "cLbV0bG9QNe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aqf.boxplot(column = ['B'], by = \"RHcat\")\n",
        "plt.title(\"Benzene by Relative Humidity\")\n",
        "plt.xlabel(\"Temperature Level (High, Low, Medium)\")\n",
        "aqf.groupby(\"RHcat\", observed = False)[\"B\"].mean()"
      ],
      "metadata": {
        "id": "KKPeo8LkQHXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Months and Seasons"
      ],
      "metadata": {
        "id": "gWDctFzuVUv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aqf['Month'] = pd.DatetimeIndex(aqf['datetime']).month\n",
        "cat_dtype2 = pd.CategoricalDtype(ordered=True)\n",
        "aqf['Month'] = aqf['Month'].astype(cat_dtype2)\n",
        "##This column is numbers, but we are treating it as an ordered category\n",
        "##Don't want to accidentally treat months as numbers (add, subtract, etc.)"
      ],
      "metadata": {
        "id": "VbZCnaAxR9uR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aqf[\"Season\"] = \"Fall\" ## All months get \"fall\"\n",
        "aqf.loc[aqf['Month']< 10,'Season'] = \"Summer\"## If month is before october, it gets \"summer\"\n",
        "aqf.loc[aqf['Month']< 7, 'Season'] = \"Spring\"## We go down the list editing only the lower months\n",
        "aqf.loc[aqf['Month']< 4, 'Season'] = \"Winter\"## until they're all categorized.\n",
        "aqf['Season'] = aqf.Season.astype(\"category\")\n",
        "order2 = [\"Winter\", \"Spring\", \"Summer\", \"Fall\"]\n",
        "cat_dtype = pd.CategoricalDtype(categories=order2, ordered=True)\n",
        "aqf['Season'] = aqf['Season'].astype(cat_dtype)"
      ],
      "metadata": {
        "id": "kQY8kgbKRspT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We do see some seasonal and monthly variation in Benzene!"
      ],
      "metadata": {
        "id": "x3COZMqfVcUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aqf.boxplot(column = ['B'], by = \"Season\")"
      ],
      "metadata": {
        "id": "szsUFhGyTcpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aqf.boxplot(column = ['B'], by = \"Month\")"
      ],
      "metadata": {
        "id": "mg43zlFgVN9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.regplot(x = aqf['Month'], y = aqf['B'], order = 8, marker = \"none\", color = \"red\")\n"
      ],
      "metadata": {
        "id": "k_656V0oWkeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlations"
      ],
      "metadata": {
        "id": "ko3PWVIDZrM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I've printed the Spearman's correlation values for Benzene with each other numeric variable (no dates or times). What we see here reflects the figures early on, where the other pollutants are much more clearly correlated with Benzene than temperature or humidity."
      ],
      "metadata": {
        "id": "p8_Hl-hccaNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notB = aqf.columns.drop([\"B\", \"Date\", \"Time\", \"datetime\", \"Tcat\", \"Month\", \"Season\"])\n",
        "print(\"Spearman's Corr Values \\n\")\n",
        "for x in notB:\n",
        "  print(x, \"\\n\", aqf.loc[:, [\"B\", x]].corr(method = 'spearman'), \"\\n\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CJ_sauU-ap5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###MLR\n",
        "Here, I have put together a MLR of NOx, NO2, with Benzene. We get a RMSE of 3.84"
      ],
      "metadata": {
        "id": "7VAs3rqrCyXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X1_train, X1_test, X2_train, X2_test, y_train, y_test = train_test_split(aqf['NOx'], aqf['NO2'], aqf['B'], test_size=0.2, random_state=42)\n",
        "\n",
        "mlr = linear_model.LinearRegression()\n",
        "x_train = pd.concat([X1_train, X2_train], axis = 1) ##With two \"x\" variables, I have to treat the data set a little differently\n",
        "x_test = pd.concat([X1_test, X2_test], axis = 1)    ## Here I'm concatenating x1 and x2 together so I can feed them into the model.\n",
        "mlr.fit(x_train, y_train)\n",
        "pred = mlr.predict(x_train)\n",
        "\n",
        "print(\"Benzene by\",X1_train.name, \"and\", X2_train.name, \\\n",
        "      \"\\nIntercept \\t\\t:\", mlr.intercept_, \\\n",
        "      \"\\nCoefficient [NOx, NO2]\\t:\", mlr.coef_, \\\n",
        "      \"\\nRMSE\\t\\t\\t:\", np.sqrt(metrics.mean_squared_error(y_train.values, pred)), \\\n",
        "      \"\\nRsquared\\t\\t:\", mlr.score(x_test, y_test))"
      ],
      "metadata": {
        "id": "TroiaPJIyUoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a 3D *interactive* figure of NOx, NO2, and Benzene, the same variables used in the MLR test above. These variables seem pretty related."
      ],
      "metadata": {
        "id": "8tz1vHDdkPSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "fig = px.scatter_3d(aqf, x = 'NOx', y = 'NO2', z = 'B')\n",
        "fig.update_traces(marker=dict(size=1))"
      ],
      "metadata": {
        "id": "pRa9aKu7ae3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, using Temp and Relative Humidity to predict B, we get a much larger RMSE of 7.25, suggesting that this model is not as helpful."
      ],
      "metadata": {
        "id": "NlLWMWspkyfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X1_train, X1_test, X2_train, X2_test, y_train, y_test = train_test_split(aqf['T'], aqf['RH'], aqf['B'], test_size=0.2, random_state=42)\n",
        "\n",
        "mlr = linear_model.LinearRegression()\n",
        "x_train = pd.concat([X1_train, X2_train], axis = 1)\n",
        "x_test = pd.concat([X1_test, X2_test], axis = 1)\n",
        "mlr.fit(x_train, y_train)\n",
        "pred = mlr.predict(x_train)\n",
        "\n",
        "print(\"Benzene by\",X1_train.name, \"and\", X2_train.name, \\\n",
        "      \"\\nIntercept \\t\\t:\", mlr.intercept_, \\\n",
        "      \"\\nCoefficient [NOx, NO2]\\t:\", mlr.coef_, \\\n",
        "      \"\\nRMSE\\t\\t\\t:\", np.sqrt(metrics.mean_squared_error(y_train.values, pred)), \\\n",
        "      \"\\nRsquared\\t\\t:\", mlr.score(x_test, y_test))"
      ],
      "metadata": {
        "id": "9E_XX_wljpzU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}